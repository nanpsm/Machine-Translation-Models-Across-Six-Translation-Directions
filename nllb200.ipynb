{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "gwZlgM_PFkPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U transformers datasets evaluate sacrebleu accelerate sentencepiece peft bitsandbytes"
      ],
      "metadata": {
        "id": "iwxDoxUM-nrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "Qp4sPuTX8XK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdtUAJM4fWPf"
      },
      "outputs": [],
      "source": [
        "import torch, time, evaluate, random\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFEcoefZhVb9"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/dataset_splits_opus100_10k\"\n",
        "\n",
        "def load_pair(pair):\n",
        "    data_files = {\n",
        "        \"train\": f\"{BASE_DIR}/{pair}/train.csv\",\n",
        "        \"validation\": f\"{BASE_DIR}/{pair}/val.csv\",\n",
        "        \"test\": f\"{BASE_DIR}/{pair}/test.csv\",\n",
        "    }\n",
        "    return load_dataset(\"csv\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBZvfYsOFpk0"
      },
      "source": [
        "# Baseline (Before Fine-tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e01m9cyclDUR"
      },
      "outputs": [],
      "source": [
        "MODEL = \"facebook/nllb-200-distilled-600M\"\n",
        "LANG = {\n",
        "    \"en\": \"eng_Latn\",\n",
        "    \"id\": \"ind_Latn\",\n",
        "    \"vi\": \"vie_Latn\",\n",
        "    \"ko\": \"kor_Hang\"\n",
        "}\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    MODEL,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.float16\n",
        ")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    MODEL,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Memory saver\n",
        "# model.gradient_checkpointing_enable()\n",
        "# model.config.use_cache = False\n",
        "\n",
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is1IjnLeun6K"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def translate_batch(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    texts,\n",
        "    src_lang: str,\n",
        "    tgt_lang: str,\n",
        "    batch_size: int = 16, # 8 if OOM\n",
        "    max_input_len: int = 256,\n",
        "    max_new_tokens: int = 256,\n",
        "    num_beams: int = 4\n",
        "):\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    tokenizer.src_lang = src_lang\n",
        "    forced_bos_token_id = tokenizer.convert_tokens_to_ids(tgt_lang)\n",
        "\n",
        "    outputs = []\n",
        "    for start in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[start:start + batch_size]\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_input_len\n",
        "        ).to(device)\n",
        "\n",
        "        # Generate translations\n",
        "        generated_tokens = model.generate(\n",
        "            **inputs,\n",
        "            forced_bos_token_id=forced_bos_token_id,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=num_beams\n",
        "        )\n",
        "\n",
        "        # Decode\n",
        "        decoded = tokenizer.batch_decode(\n",
        "            generated_tokens,\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "        outputs.extend(decoded)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR1lCbyz1lLV"
      },
      "outputs": [],
      "source": [
        "def evaluate_test(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    ds,\n",
        "    src_lang: str,\n",
        "    tgt_lang: str,\n",
        "    batch_size: int = 16, # 8 if OOM\n",
        "    max_input_len: int = 256,\n",
        "    max_new_tokens: int = 256,\n",
        "    num_beams: int = 4,\n",
        "    reverse: bool = False,\n",
        "    show_examples: bool = False,\n",
        "    num_examples: int = 3,\n",
        "    seed: int = 42\n",
        "):\n",
        "\n",
        "    bleu = evaluate.load(\"sacrebleu\")\n",
        "    chrf = evaluate.load(\"chrf\")\n",
        "\n",
        "    # Extract source and reference texts\n",
        "    if not reverse:\n",
        "        sources = ds[\"test\"][\"source\"]\n",
        "        refs    = ds[\"test\"][\"target\"]\n",
        "    else:\n",
        "        sources = ds[\"test\"][\"target\"]\n",
        "        refs    = ds[\"test\"][\"source\"]\n",
        "\n",
        "    # Translate\n",
        "    t0 = time.time()\n",
        "    preds = translate_batch(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        sources,\n",
        "        src_lang,\n",
        "        tgt_lang,\n",
        "        batch_size=batch_size,\n",
        "        max_input_len=max_input_len,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        num_beams=num_beams\n",
        "    )\n",
        "    t1 = time.time()\n",
        "\n",
        "    infer_time = t1 - t0\n",
        "    speed = len(sources) / infer_time if infer_time > 0 else 0.0\n",
        "\n",
        "    # Compute metrics\n",
        "    bleu_score = bleu.compute(\n",
        "        predictions=preds,\n",
        "        references=[[r] for r in refs]\n",
        "    )[\"score\"]\n",
        "\n",
        "    chrf_score = chrf.compute(\n",
        "        predictions=preds,\n",
        "        references=refs\n",
        "    )[\"score\"]\n",
        "\n",
        "    if show_examples:\n",
        "        print(\"\\nExamples:\\n\")\n",
        "\n",
        "        random.seed(seed)\n",
        "        indices = random.sample(range(len(sources)), min(num_examples, len(sources)))\n",
        "\n",
        "        for i, idx in enumerate(indices, 1):\n",
        "            print(\"SOURCE     :\", sources[idx])\n",
        "            print(\"PREDICTION :\", preds[idx])\n",
        "            print(\"REFERENCE  :\", refs[idx])\n",
        "\n",
        "    return {\n",
        "        \"BLEU\": float(bleu_score),\n",
        "        \"chrF\": float(chrf_score),\n",
        "        \"Speed\": float(speed)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "    (\"en_ko\", \"en\", \"ko\"),\n",
        "    (\"en_id\", \"en\", \"id\"),\n",
        "    (\"en_vi\", \"en\", \"vi\"),\n",
        "]"
      ],
      "metadata": {
        "id": "-gBnItmBnKoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn7j7vFDSMeu"
      },
      "outputs": [],
      "source": [
        "baseline_results = {}\n",
        "\n",
        "print(\"\\nEvaluation Before Fine-tuning\")\n",
        "for pair_name, src, tgt in pairs:\n",
        "\n",
        "  ds = load_pair(pair_name)\n",
        "\n",
        "  # Forward direction\n",
        "  fwd = evaluate_test(\n",
        "      base_model,\n",
        "      tokenizer,\n",
        "      ds,\n",
        "      src_lang=LANG[src],\n",
        "      tgt_lang=LANG[tgt]\n",
        "  )\n",
        "\n",
        "  baseline_results[f\"{src}->{tgt}\"] = fwd\n",
        "\n",
        "  print(f\"\\nEvaluating {src} -> {tgt} :\")\n",
        "  print(f\"BLEU            : {fwd['BLEU']:.2f}\")\n",
        "  print(f\"chrF            : {fwd['chrF']:.2f}\")\n",
        "  print(f\"Inference Speed : {fwd['Speed']:.2f} sentences/s\\n\")\n",
        "  print(\"-\"*40)\n",
        "\n",
        "  # Reverse direction\n",
        "  rev = evaluate_test(\n",
        "      base_model,\n",
        "      tokenizer,\n",
        "      ds,\n",
        "      src_lang=LANG[tgt],\n",
        "      tgt_lang=LANG[src],\n",
        "      reverse=True\n",
        "  )\n",
        "\n",
        "  baseline_results[f\"{tgt}->{src}\"] = rev\n",
        "\n",
        "  print(f\"\\nEvaluating {tgt} -> {src} :\")\n",
        "  print(f\"BLEU            : {rev['BLEU']:.2f}\")\n",
        "  print(f\"chrF            : {rev['chrF']:.2f}\")\n",
        "  print(f\"Inference Speed : {rev['Speed']:.2f} sentences/s\\n\")\n",
        "  print(\"-\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW-4SRVNFTNo"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0d_jSlxsTSe"
      },
      "outputs": [],
      "source": [
        "def preprocess(batch, src_lang, tgt_lang):\n",
        "\n",
        "    tokenizer.src_lang = LANG[src_lang]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        batch[\"source\"],\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        text_target=batch[\"target\"],\n",
        "        truncation=True,\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_model(pair_name, src, tgt):\n",
        "\n",
        "    ds = load_pair(pair_name)\n",
        "\n",
        "    # Preprocess\n",
        "    tokenized_ds = ds.map(\n",
        "        lambda x: preprocess(x, src, tgt),\n",
        "        batched=True,\n",
        "        remove_columns=ds[\"train\"].column_names\n",
        "    )\n",
        "\n",
        "    # Data collator\n",
        "    data_collator = DataCollatorForSeq2Seq(\n",
        "        tokenizer,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    # Training args\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=f\"./ft_{pair_name}\",\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=8,\n",
        "        learning_rate=2e-5,\n",
        "        num_train_epochs=1,\n",
        "        fp16=True,\n",
        "        logging_steps=100,\n",
        "        save_strategy=\"no\",\n",
        "        eval_strategy=\"no\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_ds[\"train\"],\n",
        "        data_collator=data_collator\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    start = time.time()\n",
        "    train_output = trainer.train()\n",
        "    end = time.time()\n",
        "\n",
        "    loss_df = pd.DataFrame(\n",
        "        [{\"Step\": log[\"step\"], \"Training Loss\": log[\"loss\"]}\n",
        "         for log in trainer.state.log_history\n",
        "         if \"loss\" in log and \"step\" in log]\n",
        "    )\n",
        "\n",
        "    train_info = {\n",
        "        \"train_loss\": train_output.training_loss,\n",
        "        \"training_time\": end - start,\n",
        "        \"loss_table\": loss_df\n",
        "    }\n",
        "\n",
        "    return trainer.model, train_info"
      ],
      "metadata": {
        "id": "mb2YFE0ld8eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUgIPLkIsUdS"
      },
      "outputs": [],
      "source": [
        "def finetune_and_evaluate(\n",
        "    pair_name: str,\n",
        "    src: str,\n",
        "    tgt: str,\n",
        "    model,\n",
        "    tokenizer\n",
        "):\n",
        "\n",
        "    ds = load_pair(pair_name)\n",
        "\n",
        "    # Forward direction\n",
        "    fwd = evaluate_test(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        ds,\n",
        "        src_lang=LANG[src],\n",
        "        tgt_lang=LANG[tgt]\n",
        "    )\n",
        "\n",
        "    # Reverse direction\n",
        "    rev = evaluate_test(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        ds,\n",
        "        src_lang=LANG[tgt],\n",
        "        tgt_lang=LANG[src],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        f\"{src}->{tgt}\": fwd,\n",
        "        f\"{tgt}->{src}\": rev\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_results = {}\n",
        "\n",
        "print(\"\\nEvaluation After Fine-tuning\")\n",
        "for pair_name, src, tgt in pairs:\n",
        "    print(f\"\\nFine-tuning {src} -> {tgt} :\")\n",
        "\n",
        "    ft_model, train_info = finetune_model(pair_name, src, tgt)\n",
        "\n",
        "    # Evaluate both forward and reverse directions\n",
        "    eval_results = finetune_and_evaluate(\n",
        "        pair_name=pair_name,\n",
        "        src=src,\n",
        "        tgt=tgt,\n",
        "        model=ft_model,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    finetune_results.update(eval_results)\n",
        "\n",
        "    # Print both forward and reverse directions\n",
        "    for direction, metrics in eval_results.items():\n",
        "        print(f\"BLEU            : {metrics['BLEU']:.2f}\")\n",
        "        print(f\"chrF            : {metrics['chrF']:.2f}\")\n",
        "        print(f\"Inference Speed : {metrics['Speed']:.2f} sentences/s\\n\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "    if train_info is not None:\n",
        "        if \"train_loss\" in train_info:\n",
        "            print(f\"Training Loss  : {train_info['train_loss']:.4f}\")\n",
        "        if \"training_time\" in train_info:\n",
        "            print(f\"Training Time  : {train_info['training_time']:.2f} sec\")\n",
        "        if \"loss_table\" in train_info:\n",
        "            train_info[\"loss_table\"]\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n6-direction evaluation completed after fine-tuning.\")"
      ],
      "metadata": {
        "id": "eCqcIGwgXPSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison"
      ],
      "metadata": {
        "id": "gXvmQJuxqcop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare(baseline_results, finetune_results, pairs):\n",
        "    directions = []\n",
        "\n",
        "    for _, src, tgt in pairs:\n",
        "      directions.append(f\"{src}->{tgt}\")\n",
        "      directions.append(f\"{tgt}->{src}\")\n",
        "\n",
        "    for d in directions:\n",
        "        b = baseline_results[d]\n",
        "        f = finetune_results[d]\n",
        "\n",
        "        print(\n",
        "            f\"\\nDirection:          {d}\\n\"\n",
        "            f\"BLEU (Baseline):    {b['BLEU']:.2f}\\n\"\n",
        "            f\"BLEU (Fine-tuned):  {f['BLEU']:.2f}\\n\"\n",
        "            f\"chrF (Baseline):    {b['chrF']:.2f}\\n\"\n",
        "            f\"chrF (Fine-tuned):  {f['chrF']:.2f}\\n\"\n",
        "            f\"Speed (Baseline):   {b['Speed']:.2f} sentences/s\\n\"\n",
        "            f\"Speed (Fine-tuned): {f['Speed']:.2f} sentences/s\\n\"\n",
        "            f\"{'-'*40}\"\n",
        "        )\n",
        "\n",
        "compare(baseline_results, finetune_results, pairs)"
      ],
      "metadata": {
        "id": "xSeAcoaZqiQj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}