{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanpsm/Machine-Translation-Models-Across-Six-Translation-Directions/blob/main/mbart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install evaluate sacrebleu sentencepiece"
      ],
      "metadata": {
        "id": "UAmNJkj1G-Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fRIvD_HmHCLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import evaluate\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import (\n",
        "    MBart50TokenizerFast,\n",
        "    MBartForConditionalGeneration,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer\n",
        ")"
      ],
      "metadata": {
        "id": "ATMcN_7nHDfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "MAX_CHARS = 500\n",
        "MAX_SRC_LEN = 80\n",
        "MAX_TGT_LEN = 80"
      ],
      "metadata": {
        "id": "oKo6a5f3HG1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GEN_MAX_LEN = 56\n",
        "NUM_BEAMS = 1  # greedy for speed + consistency\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device =\", device)"
      ],
      "metadata": {
        "id": "-O23LdRFHIdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/dataset_splits_opus100_10k\"\n",
        "PAIR_DIRS = {\n",
        "    \"en_ko\": f\"{BASE_DIR}/en_ko\",\n",
        "    \"en_id\": f\"{BASE_DIR}/en_id\",\n",
        "    \"en_vi\": f\"{BASE_DIR}/en_vi\",\n",
        "}"
      ],
      "metadata": {
        "id": "a9f7oLIFHLmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pair_split(pair_folder, split):\n",
        "    path = f\"{pair_folder}/{split}.csv\"\n",
        "    df = pd.read_csv(path).dropna()\n",
        "\n",
        "    # whitespace cleaning\n",
        "    df[\"source\"] = df[\"source\"].astype(str).str.strip()\n",
        "    df[\"target\"] = df[\"target\"].astype(str).str.strip()\n",
        "\n",
        "    # remove empty samples\n",
        "    df = df[(df[\"source\"] != \"\") & (df[\"target\"] != \"\")]\n",
        "\n",
        "    # max characters per sentence\n",
        "    df = df[(df[\"source\"].str.len() <= MAX_CHARS) & (df[\"target\"].str.len() <= MAX_CHARS)]\n",
        "    return df"
      ],
      "metadata": {
        "id": "ZUjWgrqnHNVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_bidir(df, src_code, tgt_code):\n",
        "    forward = pd.DataFrame({\n",
        "        \"src_text\": df[\"source\"],\n",
        "        \"tgt_text\": df[\"target\"],\n",
        "        \"src_lang\": src_code,\n",
        "        \"tgt_lang\": tgt_code\n",
        "    })\n",
        "    backward = pd.DataFrame({\n",
        "        \"src_text\": df[\"target\"],\n",
        "        \"tgt_text\": df[\"source\"],\n",
        "        \"src_lang\": tgt_code,\n",
        "        \"tgt_lang\": src_code\n",
        "    })\n",
        "    return pd.concat([forward, backward], ignore_index=True)"
      ],
      "metadata": {
        "id": "2k4dSNiSHT-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_all_splits():\n",
        "    train_parts, val_parts, test_parts = [], [], []\n",
        "\n",
        "    # en-ko\n",
        "    train_ko = load_pair_split(PAIR_DIRS[\"en_ko\"], \"train\")\n",
        "    val_ko   = load_pair_split(PAIR_DIRS[\"en_ko\"], \"val\")\n",
        "    test_ko  = load_pair_split(PAIR_DIRS[\"en_ko\"], \"test\")\n",
        "    train_parts.append(make_bidir(train_ko, \"en_XX\", \"ko_KR\"))\n",
        "    val_parts.append(make_bidir(val_ko, \"en_XX\", \"ko_KR\"))\n",
        "    test_parts.append(make_bidir(test_ko, \"en_XX\", \"ko_KR\"))\n",
        "\n",
        "    # en-id\n",
        "    train_id = load_pair_split(PAIR_DIRS[\"en_id\"], \"train\")\n",
        "    val_id   = load_pair_split(PAIR_DIRS[\"en_id\"], \"val\")\n",
        "    test_id  = load_pair_split(PAIR_DIRS[\"en_id\"], \"test\")\n",
        "    train_parts.append(make_bidir(train_id, \"en_XX\", \"id_ID\"))\n",
        "    val_parts.append(make_bidir(val_id, \"en_XX\", \"id_ID\"))\n",
        "    test_parts.append(make_bidir(test_id, \"en_XX\", \"id_ID\"))\n",
        "\n",
        "    # en-vi\n",
        "    train_vi = load_pair_split(PAIR_DIRS[\"en_vi\"], \"train\")\n",
        "    val_vi   = load_pair_split(PAIR_DIRS[\"en_vi\"], \"val\")\n",
        "    test_vi  = load_pair_split(PAIR_DIRS[\"en_vi\"], \"test\")\n",
        "    train_parts.append(make_bidir(train_vi, \"en_XX\", \"vi_VN\"))\n",
        "    val_parts.append(make_bidir(val_vi, \"en_XX\", \"vi_VN\"))\n",
        "    test_parts.append(make_bidir(test_vi, \"en_XX\", \"vi_VN\"))\n",
        "\n",
        "    train_all = pd.concat(train_parts, ignore_index=True)\n",
        "    val_all   = pd.concat(val_parts, ignore_index=True)\n",
        "    test_all  = pd.concat(test_parts, ignore_index=True)\n",
        "\n",
        "    return train_all, val_all, test_all"
      ],
      "metadata": {
        "id": "J90id_p1HYgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_all, val_all, test_all = build_all_splits()\n",
        "\n",
        "print(\"Train:\", train_all.shape, \"Val:\", val_all.shape, \"Test:\", test_all.shape)\n",
        "print(\"Train tgt_lang counts:\\n\", train_all[\"tgt_lang\"].value_counts())\n",
        "\n",
        "hf_train = Dataset.from_pandas(train_all.reset_index(drop=True))\n",
        "hf_val   = Dataset.from_pandas(val_all.reset_index(drop=True))\n",
        "hf_test  = Dataset.from_pandas(test_all.reset_index(drop=True))"
      ],
      "metadata": {
        "id": "-PJyaIqaHdMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "tok = MBart50TokenizerFast.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "hbgOnHOxHfTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(ex):\n",
        "    tok.src_lang = ex[\"src_lang\"]\n",
        "    model_in = tok(ex[\"src_text\"], max_length=MAX_SRC_LEN, truncation=True)\n",
        "    labels = tok(text_target=ex[\"tgt_text\"], max_length=MAX_TGT_LEN, truncation=True)\n",
        "    model_in[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_in"
      ],
      "metadata": {
        "id": "8wqHJsOdHjp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = hf_train.map(preprocess, remove_columns=hf_train.column_names)\n",
        "tokenized_val   = hf_val.map(preprocess, remove_columns=hf_val.column_names)\n",
        "tokenized_test  = hf_test.map(preprocess, remove_columns=hf_test.column_names)"
      ],
      "metadata": {
        "id": "HAn5yOlHHlxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_N = 20000\n",
        "VAL_N   = 2000\n",
        "TEST_N  = 2000"
      ],
      "metadata": {
        "id": "zv8U4L1tHoNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_small = tokenized_train.select(range(min(TRAIN_N, len(tokenized_train))))\n",
        "tokenized_val_small   = tokenized_val.select(range(min(VAL_N, len(tokenized_val))))\n",
        "tokenized_test_small  = tokenized_test.select(range(min(TEST_N, len(tokenized_test))))"
      ],
      "metadata": {
        "id": "piOJTn_fHpwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_test_small = hf_test.select(range(min(TEST_N, len(hf_test))))"
      ],
      "metadata": {
        "id": "uRLuyRjgHtqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MBartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "model.gradient_checkpointing_enable()\n",
        "model.config.use_cache = False\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tok, model=model)"
      ],
      "metadata": {
        "id": "HQmFpe6AHvDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"sacrebleu\")\n",
        "chrf = evaluate.load(\"chrf\")"
      ],
      "metadata": {
        "id": "Omgja0vkHwmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tok.batch_decode(preds, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tok.pad_token_id)\n",
        "    decoded_labels = tok.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds = [p.strip() for p in decoded_preds]\n",
        "    decoded_labels = [l.strip() for l in decoded_labels]\n",
        "    refs = [[l] for l in decoded_labels]\n",
        "\n",
        "    return {\n",
        "        \"bleu\": bleu.compute(predictions=decoded_preds, references=refs)[\"score\"],\n",
        "        \"chrf\": chrf.compute(predictions=decoded_preds, references=refs)[\"score\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "TOQDoensHzzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_direction_scores(model_obj, dataset_obj, src_code, tgt_code,\n",
        "                          max_n=500, batch_size=8,\n",
        "                          num_beams=NUM_BEAMS, gen_max_len=GEN_MAX_LEN):\n",
        "    subset = dataset_obj.filter(lambda x: x[\"src_lang\"] == src_code and x[\"tgt_lang\"] == tgt_code)\n",
        "    subset = subset.select(range(min(max_n, len(subset))))\n",
        "\n",
        "    if len(subset) == 0:\n",
        "        return {\"pair\": f\"{src_code}->{tgt_code}\", \"n\": 0, \"bleu\": None, \"chrf\": None, \"sents_per_sec\": None}\n",
        "\n",
        "    tok.src_lang = src_code\n",
        "    forced_id = tok.lang_code_to_id[tgt_code]\n",
        "\n",
        "    preds, refs = [], []\n",
        "    model_obj.eval()\n",
        "\n",
        "    start = time.time()\n",
        "    for i in range(0, len(subset), batch_size):\n",
        "        batch = subset[i:i+batch_size]\n",
        "        inputs = tok(\n",
        "            batch[\"src_text\"],\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_SRC_LEN\n",
        "        ).to(model_obj.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            gen = model_obj.generate(\n",
        "                **inputs,\n",
        "                forced_bos_token_id=forced_id,\n",
        "                num_beams=num_beams,\n",
        "                max_length=gen_max_len\n",
        "            )\n",
        "\n",
        "        preds.extend(tok.batch_decode(gen, skip_special_tokens=True))\n",
        "        refs.extend(batch[\"tgt_text\"])\n",
        "    elapsed = max(1e-9, time.time() - start)\n",
        "\n",
        "    preds = [p.strip() for p in preds]\n",
        "    refs  = [[r.strip()] for r in refs]\n",
        "\n",
        "    return {\n",
        "        \"pair\": f\"{src_code}->{tgt_code}\",\n",
        "        \"n\": len(subset),\n",
        "        \"bleu\": bleu.compute(predictions=preds, references=refs)[\"score\"],\n",
        "        \"chrf\": chrf.compute(predictions=preds, references=refs)[\"score\"],\n",
        "        \"sents_per_sec\": len(subset) / elapsed\n",
        "    }"
      ],
      "metadata": {
        "id": "5_H_3UT-H3f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "    (\"en_XX\",\"ko_KR\"), (\"ko_KR\",\"en_XX\"),\n",
        "    (\"en_XX\",\"id_ID\"), (\"id_ID\",\"en_XX\"),\n",
        "    (\"en_XX\",\"vi_VN\"), (\"vi_VN\",\"en_XX\"),\n",
        "]"
      ],
      "metadata": {
        "id": "hHo8sNFmH6f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASELINE_OUT = \"/content/drive/MyDrive/mbart50_baseline_per_direction.csv\"\n",
        "\n",
        "baseline_rows = [eval_direction_scores(model, hf_test, s, t, max_n=1000) for s, t in pairs]\n",
        "baseline_df = pd.DataFrame(baseline_rows).sort_values(\"pair\").reset_index(drop=True)\n",
        "print(\"=== BASELINE per direction (TEST) ===\")\n",
        "display(baseline_df)\n",
        "baseline_df.to_csv(BASELINE_OUT, index=False)\n",
        "print(\"Saved:\", BASELINE_OUT)"
      ],
      "metadata": {
        "id": "P_hh45wzH--y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/mbart50_output\",\n",
        "\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=2000,\n",
        "\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=2000,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=16,\n",
        "    num_train_epochs=1,\n",
        "\n",
        "    predict_with_generate=False,\n",
        "    generation_max_length=GEN_MAX_LEN,\n",
        "    generation_num_beams=NUM_BEAMS,\n",
        "\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_num_workers=0,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "GD8EcoktIL_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "EtlXpQu4QxFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_small,\n",
        "    eval_dataset=tokenized_val_small,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=tok\n",
        ")\n",
        "\n",
        "train_start = time.time()\n",
        "trainer.train()\n",
        "train_time_sec = time.time() - train_start"
      ],
      "metadata": {
        "id": "5s0vp6bWIMrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best/final model\n",
        "save_dir = \"/content/drive/MyDrive/mbart50_finetuned\"\n",
        "trainer.save_model(save_dir)\n",
        "tok.save_pretrained(save_dir)\n",
        "print(\"Saved to:\", save_dir)"
      ],
      "metadata": {
        "id": "GMO_YDB5ITZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model size (MB)\n",
        "model_path = os.path.join(save_dir, \"model.safetensors\")\n",
        "if os.path.exists(model_path):\n",
        "    model_size_mb = os.path.getsize(model_path) / (1024**2)\n",
        "else:\n",
        "    # fallback: directory size\n",
        "    total = 0\n",
        "    for root, _, files in os.walk(save_dir):\n",
        "        for f in files:\n",
        "            total += os.path.getsize(os.path.join(root, f))\n",
        "    model_size_mb = total / (1024**2)\n",
        "\n",
        "print(f\"Training time (sec): {train_time_sec:.2f}\")\n",
        "print(f\"Model size (MB): {model_size_mb:.2f}\")"
      ],
      "metadata": {
        "id": "LexEPMnYIcYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AFTER_OUT = \"/content/drive/MyDrive/mbart50_after_per_direction.csv\"\n",
        "COMPARE_OUT = \"/content/drive/MyDrive/mbart50_before_after_per_direction.csv\""
      ],
      "metadata": {
        "id": "kfIEwWFhIdIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = trainer.model.to(device)"
      ],
      "metadata": {
        "id": "rpIuQefSIlRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "after_rows = [eval_direction_scores(ft_model, hf_test, s, t, max_n=1000) for s, t in pairs]\n",
        "after_df = pd.DataFrame(after_rows).sort_values(\"pair\").reset_index(drop=True)\n",
        "print(\"=== AFTER finetune per direction (TEST) ===\")\n",
        "display(after_df)\n",
        "after_df.to_csv(AFTER_OUT, index=False)\n",
        "print(\"Saved:\", AFTER_OUT)"
      ],
      "metadata": {
        "id": "qfO7dSzJInG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = baseline_df.merge(after_df, on=\"pair\", suffixes=(\"_before\", \"_after\"))\n",
        "final_df[\"bleu_gain\"] = final_df[\"bleu_after\"] - final_df[\"bleu_before\"]\n",
        "final_df[\"chrf_gain\"] = final_df[\"chrf_after\"] - final_df[\"chrf_before\"]"
      ],
      "metadata": {
        "id": "HU4vHrEBIt6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add run stats columns (same for all rows)\n",
        "final_df[\"training_time_sec\"] = train_time_sec\n",
        "final_df[\"model_size_mb\"] = model_size_mb\n",
        "\n",
        "print(\"=== BEFORE vs AFTER (per direction) ===\")\n",
        "display(final_df)\n",
        "final_df.to_csv(COMPARE_OUT, index=False)\n",
        "print(\"Saved:\", COMPARE_OUT)"
      ],
      "metadata": {
        "id": "0mH5W-KgIwIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_examples(model_obj, dataset_obj, src_code, tgt_code, k=3):\n",
        "    # filter direction\n",
        "    subset = dataset_obj.filter(lambda x: x[\"src_lang\"] == src_code and x[\"tgt_lang\"] == tgt_code)\n",
        "\n",
        "    # remove non-string / empty samples (robust)\n",
        "    def ok(x):\n",
        "        s = x.get(\"src_text\", None)\n",
        "        t = x.get(\"tgt_text\", None)\n",
        "        if s is None or t is None:\n",
        "            return False\n",
        "        if not isinstance(s, str) or not isinstance(t, str):\n",
        "            return False\n",
        "        s = s.strip()\n",
        "        t = t.strip()\n",
        "        return (s != \"\") and (t != \"\")\n",
        "\n",
        "    subset = subset.filter(ok)\n",
        "    subset = subset.select(range(min(len(subset), k)))\n",
        "\n",
        "    if len(subset) == 0:\n",
        "        print(f\"No valid samples for {src_code}->{tgt_code}\")\n",
        "        return\n",
        "\n",
        "    tok.src_lang = src_code\n",
        "    forced_id = tok.lang_code_to_id[tgt_code]\n",
        "\n",
        "    # âœ… ensure list[str]\n",
        "    src_texts = [str(x).strip() for x in subset[\"src_text\"]]\n",
        "\n",
        "    inputs = tok(\n",
        "        src_texts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=MAX_SRC_LEN\n",
        "    ).to(model_obj.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        gen = model_obj.generate(\n",
        "            **inputs,\n",
        "            forced_bos_token_id=forced_id,\n",
        "            num_beams=NUM_BEAMS,\n",
        "            max_length=GEN_MAX_LEN\n",
        "        )\n",
        "\n",
        "    preds = tok.batch_decode(gen, skip_special_tokens=True)\n",
        "\n",
        "    print(f\"\\n=== Examples {src_code}->{tgt_code} ===\")\n",
        "    for i in range(len(subset)):\n",
        "        print(\"SRC :\", subset[\"src_text\"][i])\n",
        "        print(\"REF :\", subset[\"tgt_text\"][i])\n",
        "        print(\"OUT :\", preds[i])\n",
        "        print(\"---\")"
      ],
      "metadata": {
        "id": "Ap3ekKn0nVSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline examples\n",
        "for s, t in pairs:\n",
        "    show_examples(model, hf_test, s, t, k=2)\n",
        "\n",
        "# After fine-tune examples\n",
        "for s, t in pairs:\n",
        "    show_examples(ft_model, hf_test, s, t, k=2)"
      ],
      "metadata": {
        "id": "C5_H5luJI1qS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}